%
% (c) 2025 Autor, ETH ZÃ¼rich
%
% !TEX root = main.tex
% !TEX encoding = UTF-8
%

\section{Series and Power Series}
In this chapter we study series (infinite sums). They provide a framework to define many classical functions; in particular, we will use series to define trigonometric functions.

\subsection{Series of Real Numbers}

\begin{definition}{Convergent and Divergent Series}{conv_div_series}
	Let $(a_n)_{n=0}^{\infty}$ be a sequence of real numbers, and let $A \in \mathbb{R}$. We say that the series $\sum_{k=0}^{\infty} a_k$ \textbf{converges} to $A$ if
	\[
		\lim_{n \to \infty} \sum_{k=0}^{n} a_k = A.
	\]
	In other words, computing the infinite sum $\sum_{k=0}^{\infty} a_k$ means finding (if it exists) the limit of the \textbf{partial sums}
	\[
		s_n = \sum_{k=0}^{n} a_k, \qquad n \in \mathbb{N}.
	\]
	We call $a_n$ the $n$\textbf{-th term} (or $n$\textbf{-th summand}) of the series. If the limit exists, its value $A$ is the \textbf{sum of the series}. If the limit does not exist, the series is said to be \textbf{not convergent}. In particular, if the sequence of partial sums $(s_n)_{n=0}^{\infty}$ diverges to $+\infty$ (respectively, to $-\infty$), we say that the series \textbf{diverges to} $+\infty$ (respectively, \textbf{to} $-\infty$).
	This situation is therefore a specific case of a series that does not converge.
\end{definition}

\begin{proposition}{Necessary Condition for Convergence}{cond_for_conv}
	If the series $\sum_{k=0}^{\infty} a_k$  converges, then $a_n \to 0$ as $n \to \infty$.
\end{proposition}

\begin{proof}
	By assumption the partial sums $s_n = \sum_{k=0}^{n} a_k$ satisfy $s_n \to A \in \mathbb{R}$. Then for $n \geq 1$, we have 
	\[
		a_n = s_n - s_{n-1} \underset{n \to \infty}{\longrightarrow} A - A = 0. \qedhere
	\]
\end{proof}

\subsubsection*{Geometric Series}
For $q \in \mathbb{R}$, the geometric series $\sum_{k=0}^{\infty} q^k$ converges if and only if $|q| < 1$, and in this case
\[
	\sum_{k=0}^{\infty} q^k = \frac{1}{1 - q}.
\]
Indeed, if the series converges, then by Proposition \ref{prop*cond_for_conv} we must have $q^n \to 0$ as $n \to \infty$, hence $|q| < 1$. Conversely, for $|q| < 1$ one provides by induction that
\[
	s_n = \sum_{k=0}^{n} q^k = \frac{1 - q^{n+1}}{1 - q}\qquad \forall n \in \mathbb{N}, q \neq 1.
\]
Also since $|q| < 1$, $q^{n+1} \to 0$ as $n\to \infty$. Thus,
\[
	s_n = \frac{1 - q^{n+1}}{1 - q} \underset{n\to \infty}{\longrightarrow} \frac{1}{1 - q}.
\]

\subsubsection*{Harmonic Series}
The converse of Proposition \ref{prop*cond_for_conv} fails: the \textbf{harmonic series} $\sum_{k=1}^{\infty} \frac{1}{k}$ does not converge. To see this, consider $n = 2^{\ell}$ with $\ell \in \mathbb{N}$. Grouping terms gives
\begin{align*}
	\sum_{k=1}^{2^{\ell}} \frac{1}{k} &= 1 + \frac{1}{2} + \left(\frac{1}{3} + \frac{1}{4}\right) + \left(\frac{1}{5} + \hdots + \frac{1}{8}\right) + \hdots + \left(\frac{1}{2^{\ell - 1} + 1} + \hdots + \frac{1}{2^{\ell}}\right)\\
	&\geq 1 + \frac{1}{2} + \underbrace{\frac{1}{4} + \frac{1}{4}}_{=\frac{1}{2}} + \underbrace{\frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8}}_{=\frac{1}{2}} + \hdots + \underbrace{\frac{1}{2^{\ell}} + \frac{1}{2^{\ell}}}_{=\frac{1}{2}}\\
	&= 1 + \underbrace{\frac{1}{2} + \hdots + \frac{1}{2}}_{\ell \text{ - times}} = 1 + \frac{\ell}{2},
\end{align*}
which is unbounded as $\ell \to \infty$.

\begin{lemma}{Convergence of the Tail}{conv_tail}
	Let $\sum_{k=0}^{\infty} a_k$ be a series and fix $N \in \mathbb{N}$. Then $\sum_{k=0}^{\infty} a_k$ is convergent if and only if  $\sum_{k=N}^{\infty} a_k$ is convergent, and in that case
	\[
		\sum_{k=0}^{\infty} a_k = \sum_{k=0}^{N - 1} a_k + \sum_{k=N}^{\infty} a_k.
	\]
	The same equivalence holds for divergence to $+\infty$ or $-\infty$.
\end{lemma}

\begin{proof}
	For every $n \geq N$,
	\[
		\sum_{k=0}^{n} a_k = \sum_{k=0}^{N - 1} a_k + \sum_{k=N}^{n} a_k.
	\]
	Thus, the partial sums of $\sum_{k=0}^{\infty} a_k$ converge if and only if those of $\sum_{k = N}^{\infty} a_k$ do, and the identity in the statement follows by letting $n \to \infty$. The divergence case is analogous.
\end{proof}

\subsubsection{Series with Non-negative Elements}

\begin{proposition}{Non-negative Series: Convergence vs. Divergence}{non_neg_series_conv}
	Let $\sum_{k=0}^{\infty} a_k$ be a series with non-negative terms $a_k \geq 0$ for all $k \in \mathbb{N}$. Then the partial sums $s_n = \sum_{k=0}^{n} a_k$ form an increasing sequence. If $(s_n)_{n=0}^{\infty}$ is bounded, the series $\sum_{k=0}^{\infty} a_k$ converges; otherwise it diverges to $+\infty$.
\end{proposition}

\begin{proof}
	Since $a_{n+1} \geq 0$, we have $s_{n+1} = s_n + a_{n+1} \geq s_n$ for all $n \in \mathbb{N}$, so $(s_n)_{n=0}^{\infty}$ is increasing.
	
	If the sequence $(s_n)_{n=0}^{\infty}$ is bounded, then it converges by Theorem \ref{theo*conv_mono_seq}. If the partial sums are not bounded, then they diverge to $+\infty$. \qedhere
\end{proof}

\begin{remark}
	\label{rmk:series_sub_seq}
	If $\sum_{k=0}^{\infty} a_k$ has non-negative terms, then $(s_n)_{n=0}^{\infty}$ is bounded if and only if it has a bounded subsequence $(s_{n_k})_{k=0}^{\infty}$.
\end{remark}

\begin{corollary}{Comparison Test (Majorant/Minorant)}{maj_min}
	Let $\sum_{k=0}^{\infty} a_k$ and $\sum_{k=0}^{\infty} b_k$ be series with $0 \leq a_k \leq b_k$ for all $k \in \mathbb{N}$. Then
	\[
		0 \leq \sum_{k=0}^{\infty} a_k \leq \sum_{k=0}^{\infty} b_k,
	\]
	and in particular
	\begin{align*}
		\sum_{k = 0}^{\infty} b_k \text{ convergent} \quad &\Rightarrow \quad \sum_{k=0}^{\infty} a_k \text{ convergent},\\
		\sum_{k=0}^{\infty} a_k \text{ divergent to } +\infty \quad &\Rightarrow \quad \sum_{k=0}^{\infty} b_k \text{ divergent to } +\infty.
	\end{align*}
	These implications remain true if the inequalities $0 \leq a_n \leq b_n$ hold only for all $n \geq N$, for some $N \in \mathbb{N}$.
\end{corollary}

\begin{proof}
	From $a_k \leq b_k$ we get $\sum_{k=0}^{n} a_k \leq \sum_{k=0}^{n} b_k$ for all $n \in \mathbb{N}$. Therefore,
	\[
		\sum_{k=0}^{\infty} a_k = \lim_{n \to \infty} \sum_{k=0}^{n} a_k \leq \lim_{n \to \infty} \sum_{k=0}^{n} b_k = \sum_{k=0}^{\infty} b_k.
	\]
	The last part of the statement follows form Lemma \ref{lem*conv_tail}.\qedhere
\end{proof}
Under the assumptions of the corollary, $\sum_{k=0}^{\infty} b_k$ is called a \textit{majorant} of $\sum_{k=0}^{\infty}a_k$, and $\sum_{k=0}^{\infty}a_k$ a \textit{minorant} of $\sum_{k=0}^{\infty} b_k$. Hence the names \textbf{majorant} and \textbf{minorant criterion}.

\begin{proposition}{Cauchy Condensation Test}{cauchy_cond_test}
	Let $(a_k)_{k=0}^{\infty}$ be a decreasing sequence of non-negative numbers. Then
	\[
		\sum_{k=0}^{\infty} a_k \text{ converges} \quad \Leftrightarrow \quad \sum_{k=0}^{\infty} 2^k a_{2^k} \text{ converges}.
	\]
\end{proposition}

\begin{proof}
	Consider the partial sums of the series $\sum_{k=0}^{\infty} a_k$ starting form $k=2$ up to an index that is a power of 2. Since the terms $a_k$ are decreasing, the following inequalities hold:
	\begin{align*}
		\sum_{k=2}^{2^{n+1}} a_k &= a_2 + (a_3 + a_4) + (a_5 + \hdots + a_8) + \hdots + (a_{2^{n} + 1} + \hdots + a_{2^{n+1}})\\
		&\leq \underbrace{a_1}_{=1\cdot a_1} + \underbrace{(a_2 + a_2)}_{=2 \cdot a_2} + \underbrace{(a_4 + \hdots + a_4)}_{=4 \cdot a_4} + \hdots + \underbrace{(a_{2^n}) + \hdots + a_{2^{n}}}_{=2^n \cdot a_{2^n}}\\
		&= a_1 + 2a_2 + 4a_4 + \hdots + 2^n a_{2^n} = \sum_{k=0}^{n} 2^k a_{2^k},
	\end{align*}
	and similarly,
	\begin{align*}
		\sum_{k=2}^{2^{n+1}} a_k &= a_2 + (a_3 + a_4) + (a_5 + \hdots + a_8) + \hdots + (a_{2^{n} + 1} + \hdots + a_{2^{n+1}})\\
		&\geq \underbrace{a_2}_{=1\cdot a_2} + \underbrace{(a_4 + a_4)}_{=2 \cdot a_4} + \underbrace{(a_8 + \hdots + a_8)}_{=4 \cdot a_8} + \hdots + \underbrace{(a_{2^{n+1}}) + \hdots + a_{2^{n+1}}}_{=2^n \cdot a_{2^{n+1}}}\\
		&= \frac{1}{2}(2a_2 + 4a_4 + \hdots + 2^{n+1} a_{2^{n+1}}) = \frac{1}{2}\sum_{k=1}^{n+1} 2^k a_{2^k}.
	\end{align*}
	In other words,
	\[
		\sum_{k=0}^{n} 2^k a_{2^k} \geq \sum_{j=2}^{2^{n+1}} a_j \geq \frac{1}{2}\sum_{k=1}^{n+1} 2^k a_{2^k}. 
	\]
	By Remark \ref{rmk:series_sub_seq} and Corollary \ref{cor*maj_min}, the partial sums of one series are bounded if and only if those of the other are. Hence, the two series converge or diverge together. \qedhere
\end{proof}

\subsubsection{Conditional Convergence}

\begin{definition}{Absolute and Conditional Convergence}{abs_cond_conv}
	A series $\sum_{k=0}^{\infty} a_k$ is \textbf{absolutely convergent} if $\sum_{k=0}^{\infty} |a_k|$ converges. It is \textbf{conditionally convergent} if $\sum_{k=0}^{\infty} a_k$ converges but $\sum_{k=0}^{\infty} |a_k|$ diverges.
\end{definition}
A striking feature of conditionally convergent series is that their terms can be rearranged to obtain any prescribed limit.

\begin{theorem}{Riemann Rearrangement Theorem}{riemann_rearrange}
	Let $\sum_{n=0}^{\infty} a_n$ be a conditionally convergent series and let $A \in \mathbb{R}$. Then there exists a bijection $\varphi: \mathbb{N} \to \mathbb{N}$ such that
	\[
		A = \sum_{n=0}^{\infty} a_{\varphi(n)}.
	\]
\end{theorem}
The proof of this Theorem is extra material.

\subsubsection{Leibniz Criterion for Alternating Series}

\begin{definition}{Alternating Series}{alt_series}
	If $(a_k)_{k=0}^{\infty}$ is a sequence of non-negative numbers, the series
	\[
		\sum_{k=0}^{\infty} (-1)^{k} a_k
	\]
	is called the \textbf{alternating series} associated with the sequence $(a_k)_{k=0}^{\infty}$.
\end{definition}

\begin{proposition}{Leibniz Criterion}{leibniz_crit}
	Let $(a_k)_{k=0}^{\infty}$ be a monotonically decreasing sequence of non-negative numbers with $a_k \to 0$. Then the alternating series $\sum_{k=0}^{\infty} (-1)^k a_k$ converges, and for all $n \in \mathbb{N}$,
	\begin{equation}
		\label{eq:leibniz_crit}
		\sum_{k=0}^{2n+1} (-1)^k a_k \leq \sum_{k=0}^{\infty} (-1)^k a_k \leq \sum_{k=0}^{2n} (-1)^k a_k.
	\end{equation}
\end{proposition}

\begin{proof}
	Let $s_n = \sum_{k=0}^{n} (-1)^k a_k$. Since the sequence $(a_n)_{n=0}^{\infty}$ is decreasing and non-negative, we have
	\begin{align*}
		s_{2n+2} &= s_{2n} \underbrace{- a_{2n+1} + a_{2n+2}}_{\leq 0} \leq s_{2n},\\
		s_{2n+1} &= s_{2n-1} \underbrace{+ a_{2n} - a_{2n+1}}_{\geq 0} \geq s_{2n-1},\\
		s_{2n+2} &= s_{2n+1} \underbrace{+ a_{2n+2}}_{\geq 0} \geq s_{2n+1}
	\end{align*}
	for all $n\in \mathbb{N}$. In other words,
	\[
		s_1 \leq s_3 \leq \hdots \leq s_{2n-1} \leq s_{2n+1} \leq \hdots \leq s_{2n+2} \leq s_{2n} \leq \hdots \leq s_2 \leq s_0.
	\]
	This implies that the sequence $(s_{2n})_{n=0}^{\infty}$ is decreasing and bounded below, while the sequence $(s_{2n+1})_{n=0}^{\infty}$ is increasing and bounded form above. Thus, both limits $A = \lim_{n \to \infty} s_{n+1}$ and $B = \lim_{n \to \infty} s_{2n}$ exist and satify
	\begin{equation}
		\label{eq:leibniz_crit_ineq}
		s_1 \leq s_3 \leq \hdots \leq s_{2n-1} \leq s_{2n+1} \leq A \leq B \leq s_{2n+2} \leq s_{2n} \leq \hdots \leq s_2 \leq s_0.
	\end{equation}
	In particular,
	\[
		0 \leq B - A \leq s_{2n+2} - s_{2n-1} \qquad \forall n \in \mathbb{N},
	\]
	and because $a_{2n+2} \to 0$, we deduce that $A = B$.
	
	Also, Equation \eqref{eq:leibniz_crit_ineq} yields that $s_{2n+1} \leq A = B \leq s_{2n}$, which corresponds exactly to Equation \eqref{eq:leibniz_crit}. \qedhere
\end{proof}

\subsubsection*{Example (Alternating Harmonic Series)} 
The series
\[
	\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n} = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \hdots 
\]
converges by Proposition \ref{prop*leibniz_crit}, whereas $\sum_{n=0}^{\infty} \frac{1}{n}$ diverges. Hence, the alternating harmonic series is only conditionally convergent.

\subsection{Absolute Convergence}
In this section we will look at absolutely convergent series and prove some convergence criteria. As before, unless otherwise specified, all sequences consist of real numbers.

\subsubsection{Criteria for Absolute Covergence}
We begin by restating the concept of a Cauchy sequence in the context of convergent series.

\begin{theorem}{Cauchy Criterion for Series}{cauchy_crit_series}
	The series $\sum_{k=0}^{\infty} a_k$ converges if and only if, for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that for all $n > m \geq N$,
	\[
		\left|\sum_{k=m+1}^{n} a_k\right| < \varepsilon.
	\]
\end{theorem}

\begin{proof}
	By definition, the series $\sum_{k=0}^{\infty} a_k$ converges if and only if the sequence of partial sums
	\[
		s_n = \sum_{k=0}^{n} a_k
	\]
	converges. By Theorem \ref{theo*conv_cauchy_seq}, this occurs if and only if $(s_n)_{n=0}^{\infty}$ is a Cauchy sequence, i.e., $|s_n - s_m| < \varepsilon$ for all $n, m \geq N$. Since $s_n - s_m = 0$ when $n=m$, and the expression is symmetric in $n$ and $m$, it suffices to consider the case $n > m$. In this case,
	\[
		s_n - s_m = \sum_{k=m+1}^{n} a_k,
	\]
	which proves the claim.\qedhere
\end{proof}

We can now prove that absolutely convergent series do indeed converge.

\begin{proposition}{Absolute Convergence Implies Convergence}{abs_conv_conv}
	If a series $\sum_{n=0}^{\infty}a_n$ converges absolutely, then it converges and satisfies the generalized triangle inequality
	\[
		\left|\sum_{n=0}^{\infty} a_n\right| \leq \sum_{n=0}^{\infty} |a_n|.
	\]
\end{proposition}

\begin{proof}
	Since $\sum_{n=0}^{\infty} |a_n|$ converges, by the Cauchy criterion (Theorem \ref{theo*cauchy_crit_series}) there exists $N \in \mathbb{N}$ such that, for all $n > m \geq N$,
	\[
	\sum_{k=m+1}^{n} |a_k| < \varepsilon.
	\]
	By the triangle inequality,
	\[
	\left|\sum_{k=m+1}^{n} a_k\right| \leq \sum_{k=m+1}^{n} |a_k| < \varepsilon,
	\]
	so $\sum_{n=0}^{\infty} a_n$ also satisfies the Cauchy criterion and therefore converges.
	
	Moreover, again by the triangle inequality,
	\[
	\left|\sum_{k=0}^{n} a_k\right| \leq \sum_{k=0}^{n} |a_k| \leq \sum_{k=0}^{\infty} a_k \qquad \forall n \in \mathbb{N},
	\]
	and taking the limit as $n \to \infty$ gives the desired inequality.\qedhere
\end{proof}

We now establish two classical criteria guaranteeing absolute convergence. In their proof, we repeatedly use the following fact:
\begin{remark}
	\label{rmk:for_root_crit}
	If a sequence $(x_n)_{n=0}^{\infty}$ converges to $\alpha \in \mathbb{R}$, then Proposition \ref{prop*lim_ineq} implies the following facts:
	\begin{enumerate}
		\item[(i)] for any $q > \alpha$ there exists $N \in \mathbb{N}$ such that $x_n < q$ for all $n \geq N$;
		\item[(ii)] for any $r < \alpha$ there exists $N \in \mathbb{N}$ such that $x_n > r$ for all $n \geq N$.
	\end{enumerate}
\end{remark}

\begin{proposition}{Cauchy Root Criterion}{cauchy_root_crit}
	Given a sequence $(a_n)_{n=0}^{\infty}$, define
	\[
		\alpha = \limsup_{n \to \infty} \sqrt[n]{|a_n|} \in \mathbb{R} \cup \{\infty\}.
	\]
	Then,
	\[
		\alpha < 1 \;\Rightarrow \; \sum_{n=0}^{\infty} a_n \text{ converges absolutely,} \qquad \alpha > 1 \;\Rightarrow\; \sum_{n=0}^{\infty} a_n \text{ does not converge}.
	\]
\end{proposition}

\begin{proof}
	Suppose $\alpha < 1$ and set $q = \frac{1 + \alpha}{2}$, so that $q \in (\alpha, 1)$. By definition,
	\[
	\limsup_{n \to \infty} \sqrt[n]{|a_n|} = \lim_{n \to \infty} \sup_{k\geq n} \sqrt[k]{|a_k|}.
	\]
	Thus, $x_n = \sup_{k\geq n} \sqrt[k]{|a_k|} \to \alpha$. Since $\alpha < q$, Remark \ref{rmk:for_root_crit}(i) implies the existence of $N \in \mathbb{N}$ such that
	\[
	x_N = \sup_{k\geq N} \sqrt[k]{|a_k|} < q \qquad \forall k \geq N,
	\]
	therefore,
	\[
	|a_k| < q^k \qquad \forall k \geq N.
	\]
	Since $q < 1$, $\sum_{k=N}^{\infty} |a_k|$ converges by comparison with the geometric series, so $\sum_{n=0}^{\infty} a_n$ converges absolutely.
	
	If $\alpha > 1$, since the limsup is an accumulation point (Theorem \ref{theo*limsup_acc_pt}), Proposition \ref{prop*subseq_acc_pt} implies the existence of a subsequence $(a_{n_k})_{k=0}^{\infty}$ such that $\lim_{k \to \infty} \sqrt[n_k]{|a_{n_k}|} = \alpha$. Hence, thanks to Remark \ref{rmk:for_root_crit}(ii) with $r=1$, $\sqrt[n_k]{|a_{n_k}|} > 1$ for all $k$ large, or equivalently, $|a_{n_k}| > 1$ for large $k$. In particular the sequence $(a_n)_{n=0}^{\infty}$ does not converge to 0. Recalling Proposition \ref{prop*cond_for_conv}, this implies that the series $\sum_{n=0}^{\infty} a_n$ does not converge.\qedhere
\end{proof}

\begin{remark}
	If $\alpha = 1$, the root criterion is inconclusive.
\end{remark}

\begin{proposition}{D'Alambert's Quotient Criterion}{quot_crit}
	Given a sequence $(a_n)_{n=0}^{\infty}$ with $a_n \neq 0$ for all $n$, assume that
	\[
		\lim_{n \to \infty} \frac{|a_{n+1}|}{|a_n|} = \alpha \in [0, \infty).
	\]
	Then
	\[
		\alpha < 1 \; \Rightarrow \; \sum_{n=0}^{\infty} a_n \text{ converges absolutely,} \qquad \alpha > 1 \;\Rightarrow\; \sum_{n=0}^{\infty} a_n \text{ does not converge.}
	\]
\end{proposition}

\begin{proof}
	The proof parallels that of the root criterion.
	
	If $\alpha < 1$. set $q = \frac{1 + \alpha}{2} \in (\alpha, 1)$. Since $\frac{|a_{n+1}|}{|a_n|} \to \alpha$ and $\alpha < q$, by Remark \ref{rmk:for_root_crit}(i) there exists $N \in \mathbb{N}$ such that
	\[
		\frac{|a_{k+1}|}{|a_k|} < q \qquad \forall k \geq N.
	\]
	This gives
	\[
		|a_k| = \frac{|a_k|}{|a_{k-1}|}\cdot \frac{|a_{k-1}|}{|a_{k-2}|} \cdot \hdots \cdot \frac{|a_{N+1}|}{|a_N|} \cdot |a_{N}|
		<
		q^{k-N} |a_N| = \frac{|a_N|}{q^N} q^k \qquad \forall k \geq N.
	\]
	Since $q < 1$, the geometric comparison test shows that $\sum_{n=0}^{\infty} a_n$ converges absolutely.
	
	If $\alpha > 1$, then Remark \ref{rmk:for_root_crit}(ii) with $r = 1$ implies the existence of $N \in \mathbb{N}$ such that
	\[
		\frac{|a_{k+1}|}{|a_k|} > 1 \qquad \forall k \geq N.
	\]
	In particular,
	\[
		|a_k| = \frac{|a_k|}{|a_{k-1}|}\cdot \frac{|a_{k-1}|}{|a_{k-2}|} \cdot \hdots \cdot \frac{|a_{N+1}|}{|a_N|} \cdot |a_{N}|
		> |a_N| \qquad \forall k \geq N.
	\]
	Hence, $(a_n)_{n=0}^{\infty}$ does not tend to 0, and by Proposition \ref{prop*cond_for_conv} the series does not converge.\qedhere
\end{proof}

\subsubsection{Reordering Series}
\begin{theorem}{Rearrangement of Absolutely Convergent Series}{rearr_abs_conv}
	Let $\sum_{n=0}^{\infty} a_n$ be an absolutely convergent series, and let $\varphi: \mathbb{N} \to \mathbb{N}$ be a bijection. Then $\sum_{n=0}^{\infty} a_{\varphi(n)}$ is absolutely convergent, and
	\begin{equation}
		\label{eq:reordered_series}
		\sum_{n=0}^{\infty} a_n = \sum_{n=0}^{\infty} a_{\varphi(n)}.
	\end{equation}
\end{theorem}

\begin{proof}
	Fix $\varepsilon > 0$. Since $\sum_{n=0}^{\infty} |a_n|$ converges, there exists $N \in \mathbb{N}$ such that
	\[
		\sum_{k=N+1}^{\infty} |a_k| < \frac{\varepsilon}{2}.
	\]
	Let
	\[
		M = \max\{\varphi^{-1}(0), \hdots , \varphi^{-1}(N)\}.
	\]
	Equivalently, $M \in \mathbb{N}$ is the smallest number such that
	\[
		\{a_0, \hdots , a_N\} \subseteq \{a_{\varphi(0)}, \hdots , a_{\varphi(M)}\}
	\]
	Then
	\[
		\{a_0, \hdots , a_N\} \subseteq \{a_{\varphi(0)}, \hdots , a_{\varphi(n)}\} \qquad \forall n \geq M.
	\]
	Therefore,
	\[
		\sum_{\ell = 0}^{n} a_{\varphi(\ell)} - \sum_{k=0}^{N} a_k = \sum_{\underset{\varphi(\ell) > N}{0 \leq \ell \leq n}} a_{\varphi(\ell)}.
	\]
	Moreover, since all indices $\varphi(\ell) > N$ with $0\leq \ell \leq n$ correspond to terms among $\{|a_k| \;|\; k \geq N+1\}$, we have
	\[
	\sum_{\underset{\varphi(\ell) >N}{0 \leq \ell \leq n}} |a_{\varphi(\ell)}| \leq \sum_{k = N+1}^{\infty} |a_k|.
	\]
	This implies that, for $n \geq M$, we can estimate
	\begin{align*}
		\bigg|\sum_{\ell = 0}^{n} a_{\varphi(\ell)} - \sum_{k=0}^{\infty} a_k\bigg| &= \bigg|\sum_{\ell = 0}^{n} a_{\varphi(\ell)} - \sum_{k=0}^{N} a_k - \sum_{k=N+1}^{\infty} a_k\bigg| = \bigg|\sum_{\underset{\varphi(\ell) > N}{0 \leq \ell \leq n}} a_{\varphi(\ell)} - \sum_{k=N+1}^{\infty} a_k\bigg|\\
		&\leq \sum_{\underset{\varphi(\ell) > N}{0 \leq \ell \leq n}} |a_{\varphi(\ell)}| + \sum_{k=N+1}^{\infty} |a_k| \leq 2\,\sum_{k=N+1}^{\infty} |a_k| < \varepsilon.
	\end{align*}
	This shows that
	\[
	\sum_{\underset{\varphi(\ell) > N}{0 \leq \ell \leq n}} a_{\varphi(\ell)} \longrightarrow \sum_{k=0}^{\infty} a_k \quad \text{as } n\to \infty,
	\]
	which proves the identity \eqref{eq:reordered_series}. Applying the same reasoning to $\sum_{n=0}^{\infty} |a_n|$ shows that $\sum_{\ell = 0}^{\infty} |a_{\varphi(\ell)}| = \sum_{n=0}^{\infty} |a_n| < \infty$, hence $\sum_{\ell = 0}^{\infty} a_{\varphi(\ell)}$ is absolutely convergent.
	\qedhere
\end{proof}

\subsubsection{Product of Series}

\begin{theorem}{Product Theorem}{prod_theo}
	Let $\sum_{n=0}^{\infty} a_n$ and $\sum_{n=0}^{\infty} b_n$ be absolutely convergent series, and let $\alpha: \mathbb{N} \to \mathbb{N} \times \mathbb{N}$ be a bijection. Writing $\alpha(n) = (\alpha_1(n), \alpha_2(n))$, one has
	\begin{equation}
		\label{eq:product_series}
		\left(\sum_{n=0}^{\infty} a_n\right)\left(\sum_{n=0}^{\infty} b_n\right) = \sum_{n=0}^{\infty} a_{\alpha_1(n)} b_{\alpha_2(n)},
	\end{equation}
	and the series on the right converges absolutely.
\end{theorem}

\begin{proof}
	Consider first a bijection $\alpha: \mathbb{N} \to \mathbb{N} \times \mathbb{N}$, written as $\alpha(n) = (\alpha_1(n), \alpha_2(n))$, such that
	\[
		\{a(k) \;|\; 0\leq k < n^2\} = \{0, 1, \hdots, n-1\} \qquad \forall n \in\mathbb{N}. 
	\]
	For example, $(\alpha(n))_{n=0}^{\infty}$ could traverse the grid as shown in the lecture.
	Then, for every $n \in \mathbb{N}$,
	\[
	\sum_{k=0}^{n^2 - 1} |a_{\alpha_1(k)}| |b_{\alpha_2(k)}| = \left(\sum_{\ell = 0}^{n-1} |a_{\ell}|\right) \left(\sum_{m=0}^{n-1} |b_m|\right).
	\]
	Since the right-hand side is bounded by
	\[
	\left(\sum_{\ell = 0}^{\infty} |a_{\ell}|\right) \left(\sum_{m=0}^{\infty} |b_m|\right),
	\]
	we have
	\[
	\sup_{n \in \mathbb{N}} \sum_{k=0}^{n^2 - 1} |a_{\alpha_1(k)}| |b_{\alpha_2(k)}| \leq 	\left(\sum_{\ell = 0}^{\infty} |a_{\ell}|\right) \left(\sum_{m=0}^{\infty} |b_m|\right) < \infty.
	\]
	This implies that the series $\sum_{k=0}^{\infty} a_{\alpha_1(k)} b_{\alpha_2(k)}$. In particular, since it converges, its value can be computed along every subsequence, therefore
	\[
	\sum_{k=0}^{\infty} a_{\alpha_1(k)} b_{\alpha_2(k)} = \lim_{n \to \infty} \sum_{k=0}^{n^2 - 1} a_{\alpha_1(k)} b_{\alpha_2(k)}
	\]
	Now writing the identity
	\[
	\sum_{k=0}^{n^2 - 1} a_{\alpha_1(k)} b_{\alpha_2(k)} = \left(\sum_{\ell = 0}^{n-1} a_{\ell}\right) \left(\sum_{m=0}^{n-1} b_m\right),
	\]
	and taking the limit as $n \to \infty$, Proposition \ref{prop*lim_op}(2.) gives
	\begin{align*}
		\sum_{k=0}^{\infty} a_{\alpha_1(k)} b_{\alpha_2(k)} &= \lim_{n \to \infty} \sum_{k=0}^{n^2 - 1} a_{\alpha_1(k)} b_{\alpha_2(k)} = \\
		&= \left( \lim_{n \to \infty}\sum_{\ell = 0}^{n-1} a_{\ell}\right) \left( \lim_{n \to \infty} \sum_{m=0}^{n-1} b_m\right) = \left(\sum_{\ell = 0}^{\infty} a_{\ell}\right) \left(\sum_{m=0}^{\infty} b_m\right),
	\end{align*}
	which proves Equation \eqref{eq:product_series} for this specific bijection $\alpha$.
	
	For an arbitrary bijection $\beta: \mathbb{N} \to \mathbb{N} \times \mathbb{N}$, define $\varphi = \alpha^{-1} \circ \beta: \mathbb{N} \to \mathbb{N}$. Then $\beta = \alpha \circ \varphi$ and writing $\beta(n) = (\beta_1(n), \beta_2(n)) = (\alpha_1(\varphi(n)), \alpha_2(\varphi(n)))$, the rearrangement Theorem \ref{theo*rearr_abs_conv} yields
	\[
	\sum_{n=0}^{\infty} a_{\beta_1(n)} b_{\beta_2(n)} = \sum_{n=0}^{\infty} a_{\alpha_1(\varphi(n))} b_{\alpha_2(\varphi(n))} = \sum_{n=0}^{\infty} a_{\alpha_1(n)} b_{\alpha_2(n)} = \left(\sum_{n=0}^{\infty} a_n\right) \left(\sum_{n=0}^{\infty} b_n\right). \qedhere
	\] 
\end{proof}

\begin{corollary}{Cauchy Product}{cauchy_prod}
	If $\sum_{n=0}^{\infty} a_n$ and $\sum_{n=0}^{\infty} b_n$ are absolutely convergent, then
	\[
		\left(\sum_{n=0}^{\infty} a_n\right) \left(\sum_{n=0}^{\infty} b_n\right) = \sum_{n = 0}^{\infty} \left(\sum_{k=0}^{n} a_{n-k} b_k\right),
	\]
	and the series on the right converges absolutely.
\end{corollary}

\begin{proof}
	Consider the bijection $\alpha: \mathbb{N} \to \mathbb{N} \times \mathbb{N}$ defined as
	\begin{align*}
		&\alpha(0) = (0,0), \quad \alpha(1) = (1,0), \quad \alpha(2) = (0,1), \quad \alpha(3) = (2,0), \quad \alpha(4) = (1,1), \hdots ,\\
		&\alpha(20) = (0, 5), \hdots , \alpha(31) = (4, 3), \hdots , \alpha(49) = (5,4), \hdots \text{etc.}
	\end{align*}
	By Theorem \ref{theo*prod_theo},
	\[
		\left(\sum_{n=0}^{\infty} a_n\right) \left(\sum_{n=0}^{\infty} b_n\right) = \sum_{n=0}^{\infty} a_{\alpha_1(n)} b_{\alpha_2(n)}.
	\]
	Listing the terms explicitly and grouping them by diagonals, we obtain
	\begin{align*}
				\sum_{n=0}^{\infty} a_{\alpha_1(n)} b_{\alpha_2(n)} &= a_0b_0 + (a_0 b_1 + a_1 b_0) + (a_2 b_0 + a_1 b_1 + a_0 b_2)\\
				&+ (a_3 b_0 + a_2 b_1 + a_1 b_2 + a_0 b_3) + \hdots\\
				&= \sum_{n=0}^{\infty} \bigg(\sum_{\underset{j + k = n}{j,k \geq 0}} a_j b_k\bigg) = \sum_{n=0}^{\infty} \bigg(\sum_{k=0}^{n} a_{n-k} b_k\bigg).
	\end{align*}
	Finally, absolute convergence follows from the triangle inequality and Theorem \ref{theo*prod_theo}, i.e.,
	\[
		\sum_{n=0}^{\infty} \bigg|\sum_{k=0}^{n} a_{n-k} b_k\bigg| \leq \sum_{n=0}^{\infty} \sum_{k=0}^{n} |a_{n-k} b_k| = \sum_{n=0}^{\infty} |a_{\alpha_1(n)}| |b_{\alpha_2(n)}| < \infty. \qedhere
	\]
\end{proof}

\subsection{Series of Complex Numbers}
To define the notion of a convergent series in $\mathbb{C}$, it is sufficient to consider separately the corresponding series of its real and imaginary parts in $\mathbb{R}$.

\begin{definition}{Series of Complex Numbers}{series_cmplx}
	Let $(z_n)_{n=0}^{\infty} = (x_n + iy_n)_{n=0}^{\infty}$ be a sequence of complex numbers, and let $Z = A + iB \in \mathbb{C}$. The series $\sum_{n=0}^{\infty} z_n$ is said to \textbf{converge} to $Z$ if both real series $\sum_{n=0}^{\infty} x_n$ and $\sum_{n=0}^{\infty} y_n$ converge, with limits $A$ and $B$, respectively, i.e.,
	\[
		\sum_{n=0}^{\infty} x_n = A, \qquad \sum_{n=0}^{\infty} y_n = B.
	\]
	We say that
	$\sum_{n=0}^{\infty} z_n$ \textbf{converges absolutely} if the series of moduli $\sum_{n=0}^{\infty} |z_n|$ converges.
\end{definition}

Whenever the series $\sum_{n=0}^{\infty} z_n$ and $\sum_{n=0}^{\infty} w_n$ converge absolutely, their sum and product are given (exactly as in the real case) by
\begin{subequations}
	\begin{align}
		\label{eq:sum_cmplx_series}
		\sum_{n=0}^{\infty} z_n + \sum_{n=0}^{\infty} w_n &= \sum_{n=0}^{\infty} z_n + w_n\\
		\label{eq:prod_cmplx_series}
		\left(\sum_{n=0}^{\infty} z_n\right) \left(\sum_{n=0}^{\infty} w_n\right) &= \sum_{n=0}^{\infty} \left(\sum_{k=0}^{n} z_{n-k} w_k\right).
	\end{align}
\end{subequations}

\begin{remark}
	\label{rmk:conv_real_im}
	Let $(z_n)_{n=0}^{\infty} = (x_n + iy_n)_{n=0}^{\infty}$ be a sequence of complex numbers, and assume that the series $\sum_{n=0}^{\infty} |z_n|$ converges. Since
	\[
		0\leq |x_n| \leq |z_n|, \qquad 0 \leq |y_n| \leq |z_n|, \qquad \forall n\in \mathbb{N},
	\]
	the Majorant Criterion (Corollary \ref{cor*maj_min}) implies that both $\sum_{n=0}^{\infty} |x_n|$ and $\sum_{n=0}^{\infty} |y_n|$ converge. Hence, the series of real and imaginary parts are absolutely convergent.
	
	Conversely since $|z_n| \leq |x_n| + |y_n|$, the absolute convergence of $\sum_{n=0}^{\infty} x_n$ and $\sum_{n=0}^{\infty} y_n$ also implies the absolute convergence of $\sum_{n=0}^{\infty} z_n$. Therefore, absolute convergence in $\mathbb{C}$ is equivalent to absolute convergence of the real and imaginary parts.
\end{remark}

\subsection{Power Series}
\label{sec:pwr_series}
Our next goal is to investigate power series. These are series where the terms are powers of the variable $x \in \mathbb{R}$ (or $z \in \mathbb{C}$, if one considers complex power series) multiplied by coefficients.

\subsubsection{Radius of Convergence}

\begin{definition}{Power Series}{pwr_series}
	A \textbf{power series} with real coefficients is a series of the form
	\[
		\sum_{n=0}^{\infty} a_n x^n,
	\]
	where $(a_n)_{n=0}^{\infty}$ is a sequence in $\mathbb{R}$ and $x \in \mathbb{R}$. Here $x$ is the \textbf{variable} and $a_n$ is the \textbf{coefficient} of $x^n$.
	By convention, we set $x^0 = 1$ for all $x \in \mathbb{R}$, including $x=0$. In other words, the first term of the power series is always $a_0$.
\end{definition}
Addition and Multiplication of power series are given by
\begin{align*}
		\sum_{n=0}^{\infty}a_n x^n + \sum_{n=0}^{\infty} b_n x^n &= \sum_{n=0}^{\infty} (a_n + b_n) x^n,\\
		\left(\sum_{n=0}^{\infty} a_n x^n\right) \left(\sum_{n=0}^{\infty} b_n x^n\right) &= \sum_{n=0}^{\infty} \left(\sum_{k=0}^{n} a_{n-k} x^{n-k} b_k x^k\right) = \sum_{n=0}^{\infty} \left(\sum_{k=0}^{\infty} a_{n-k} b_k\right)x^n,
\end{align*}
where the product formula follows from Corollary \ref{cor*cauchy_prod}.

A power series is a polynomial whenever only finitely many coefficients are \textit{non-zero}.

\begin{definition}{Radius of Convergence}{radius_conv}
	Let $\sum_{n=0}^{\infty} a_n x^n$ be a power series, and define
	\[
		\rho := \limsup_{n \to \infty} \sqrt[n]{|a_n|}.
	\]
	The \textbf{radius of convergence} is defined as 
	\[
		R := \begin{cases}
			0, \qquad &\rho = \infty,\\
			\rho^{-1}, \qquad &0  < \rho < \infty,\\
			\infty, \qquad &\rho = 0.
		\end{cases}
	\]
\end{definition}

In the following, when we write $R \in [0, \infty]$, we mean that $R$ is either a non-negative real number or $R = \infty$.

\begin{theorem}{Convergence of Power Series}{conv_pwr_series}
	Let $\sum_{n=0}^{\infty}a_n x^n$ be a power series with radius of convergence $R \in (0, \infty]$. Then $\sum_{n=0}^{\infty}a_nx^n$ converges absolutely for all $x \in \mathbb{R}$ with $|x| < R$, and does not converge for all $x \in \mathbb{R}$ with $|x| > R$. In particular, for $x \in (-R, R)$, we can define the function $f(x) = \sum_{n=0}^{\infty} a_n x^n$.
\end{theorem}

\begin{proof}
	Let $x \in \mathbb{R}$, and write $\rho = \limsup_{n \to \infty} \sqrt[n]{|a_n|}$ as in Definition \ref{def*radius_conv}. Then
	\[
		\limsup_{n \to \infty} \sqrt[n]{|a_n x^n|} = \left(\limsup_{n \to \infty} \sqrt[n]{|a_n|}\right) |x| = \rho |x|.
	\]
	By the root criterion (see Proposition \ref{prop*cauchy_root_crit}), the series $\sum_{n=0}^{\infty}a_n x^n$ converges absolutely if$\rho |x| < 1$, and does not converge if $\rho |x| > 1$ (in particular if $\rho = 0$ it converges for all $x \in \mathbb{R}$). Since $R = \frac{1}{\rho}$, the result follows. \qedhere
\end{proof}

\begin{theorem}{Continuity of Power Series}{cont_pwr_series}
	Let $\sum_{n=0}^{\infty} a_n x^n$ be a power series with radius of convergence $R \in (0, \infty]$, and define polynomials $f_n(x) = \sum_{k=0}^{n} a_k x^k$. For any $r \in (0, R)$, the sequence $(f_n)_{n=0}^{\infty}$ converges uniformly to $f$ on $[-r, r]$. In particular, the power series defines a continuous function $f:(-R, R) \to \mathbb{R}$.
\end{theorem}

\begin{proof}
	By Theorem \ref{theo*conv_pwr_series} with $x = r$, the series $\sum_{n=0}^{\infty} |a_n| r^n$ converges, where $r < R$. Hence, for every $\varepsilon > 0$, there exists $N \in \mathbb{N}$ such that
	\[
	\sum_{k=N+1}^{\infty} |a_k| r^k < \varepsilon.
	\]
	Thus, for all $x \in [-r, r]$ and all $n \geq N$,
	\[
	|f_n(x) - f(x)| = \left|\sum_{k=n+1}^{\infty} a_k x^k\right| \leq \sum_{k=n+1}^{\infty} |a_k||x^k| \leq \sum_{k=N+1}^{\infty} |a_k| r^k < \varepsilon.
	\]
	This shows that $(f_n)_{n=0}^{\infty}$ converges uniformly to $f$ on $[-r, r]$. Since each $f_n$ is continuous (being a polynomial), Theorem \ref{theo*cont_unif_conv} implies that $f$ is continuous on $[-r, r]$. As $r < R$ is arbitrary, $f$ is continuous on $(-R, R)$.\qedhere
\end{proof}

\subsubsection*{Example}
In general, the partial sums $f_n(x) = \sum_{k=0}^{n} a_k x^k$ do \textit{not} converge uniformly to $f(x) = \sum_{k=0}^{\infty} a_k x^k$ on the whole interval $(-R, R)$.

To see this, consider the geometric series $\sum_{n=0}^{\infty} x^n$. Its radius of Convergence is $R = 1$, and on $(-1, 1)$ we have $f(x) = \sum_{n=0}^{\infty} x^n = \frac{1}{1 - x}$. If the convergence on $(-1, 1)$ were uniformly, then applying the notion of uniform convergence with $\varepsilon = 1$ would give $N \in \mathbb{N}$ such that, for all $n \geq N$ and $x \in (-1, 1)$,
\[
	\left|\sum_{k=0}^{n} x^k - \frac{1}{1 - x}\right| < 1.
\]
Taking $n = N$ and using the triangle inequality, we would get
\[
	\left|\frac{1}{1 - x}\right| < 1 + \left|\sum_{k=0}^{N} x^k\right| \leq 1 + \sum_{k=0}^{N} |x^k| \leq 1 + (N + 1) = N + 2 \qquad \forall x \in (-1, 1),
\]
a contradiction since $\lim_{x\to 1^{-}} \frac{1}{1 - x} = \infty$.


\begin{proposition}{Radius of Convergence of Sum and Product}{radius_conv_sum_prod}
	Let $R \geq 0$, and let $\sum_{n=0}^{\infty} a_n x^n$ and $\sum_{n=0}^{\infty} b_n x^n$ be power series with radius of convergence of at least $R$. Then their sum and their Cauchy product also have radius of convergence of at least $R$.
\end{proposition}

\begin{proof}
	By linearity and Corollary \ref{cor*cauchy_prod}, the absolute convergence of $\sum_{n=0}^{\infty} a_nx^n$ and $\sum_{n=0}^{\infty} b_nx^n$ for $|x| < R$ implies that
	\[
		\sum_{n=0}^{\infty} (a_n + b_n) x^n, \qquad \left(\sum_{n=0}^{\infty} a_n x^n\right) \left(\sum_{n=0}^{\infty} b_n x^n\right) = \sum_{n=0}^{\infty} \left(\sum_{k=0}^{n} a_{n-k} b_k\right) x^n
	\]
	both converge absolutely for $|x| < R$. Since a power series cannot converge for $|x| > R$, each has radius of convergence of at least $R$. \qedhere
\end{proof}

\subsubsection{Complex Power Series}

\begin{definition}{Complex Power Series}
	A \textbf{complex power series} with complex coefficients is a series of the form
	\[
		\sum_{n=0}^{\infty} a_n z^n,
	\]
	where $(a_n)_{n=0}^{\infty}$ is a sequence in $\mathbb{C}$ and $z \in \mathbb{C}$. Again by convention, we set $z^0 = 1$ for all $z \in \mathbb{C}$, including $z = 0$.
\end{definition}
Addition and multiplication are defined as in the real case.

\begin{theorem}{Convergence of Complex Power Series}{conv_cmplx_pwr_series}
	Let $\sum_{n=0}^{\infty} a_nz^n$ be a complex power series with radius of convergence $R \in (0, \infty]$. Then the series $\sum_{n=0}^{\infty} a_nz^n$ converges absolutely for all $z \in \mathbb{C}$ with $|z| < R$, and diverges for all $z \in \mathbb{C}$ with $|z| > R$. In particular, for $|z| < R$ one can define the (complex-valued) function
	\[
		f(z) = \sum_{n=0}^{\infty} a_n z^n.
	\]
\end{theorem}

\subsection{Exponential and Trigonometric Functions}

\subsubsection{The Exponential Map as a Power Series}
We now show that the exponential map can also be defined via the \textbf{exponential series}
\begin{equation}
	\label{eq:exp}
	\exp(x) = e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}.
\end{equation}
Since $\frac{n!}{(n+1)!} = \frac{1}{(n+1)} \to 0$ as $n \to \infty$, it follows directly from the quotient criterion that this series has infinite radius of convergence. Hence, Theorem \ref{theo*cont_pwr_series} implies that the right-hand side of Equation \eqref{eq:exp} defines a continuous function on $\mathbb{R}$.

\begin{proposition}{Exponential Map as a Power Series}{exp_pwr_series}
	For every $x \in \mathbb{R}$,
	\[
		\sum_{k=0}^{\infty} \frac{x^k}{k!} = \lim_{n \to \infty} \left(1 + \frac{x}{n}\right)^n.
	\]
\end{proposition}

\begin{definition}{The Complex Exponential Map}{cmplx_exp}
	The \textbf{complex exponential map} is the function $\exp:\mathbb{C} \to \mathbb{C}$ defined by
	\[
		\exp(z) = e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!}, \qquad z \in \mathbb{C}.
	\]
\end{definition}

\begin{theorem}{Properties of the Complex Exponential}{prop_cmplx_exp}
	The complex exponential map $\exp: \mathbb{C} \to \mathbb{C}$ is continuous, and for all $z, w \in \mathbb{C}$,
	\[
		e^{z + w} = e^z e^w, \quad |e^z| = e^{\operatorname{Re}(z)}.
	\]
	In particular, $|e^{ix}| = 1$ for all $x \in \mathbb{R}$.
\end{theorem}

\subsubsection{Sine and Cosine}
Given $x \in \mathbb{R}$, we split the power series of $e^{ix}$ into its even and odd terms, i.e.,
\[
	e^{ix} = \sum_{n=0}^{\infty} \frac{i^n}{n!}x^n = \sum_{n = 0}^{\infty} \frac{i^{2n}}{(2n)!} x^{2n} + \sum_{n=0}^{\infty} \frac{i^{2n+1}}{(2n+1)!}x^{2n+1}.
\]
Since $i^{2n} = (-1)^n$ and $i^{2n+1} = i (-1)^n$, we obtain
\[
	e^{ix} = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n} + i \sum_{n=0}^{\infty} \frac{(-1)^{n}}{(2n + 1)!} x^{2n+1}.
\]
This motivates the following definition of the \textbf{sine} and \textbf{cosine functions}, i.e.,
\begin{equation}
	\label{eq:sin_cos}
	\sin(x) := \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n + 1)!}x^{2n+1}, \qquad \cos(x) := \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n},
\end{equation}
so that the identity
\[
	e^{ix} = \cos(x) + i\sin(x)
\]
holds for all $x \in \mathbb{R}$.

As for the exponential series, radius of convergence of the power series in Equation \eqref{eq:sin_cos} is infinite. Therefore, by Theorems \ref{theo*conv_pwr_series} and \ref{theo*cont_pwr_series}, $\sin$ and $\cos$ are continuous on $\mathbb{R}$.

Since $(-x)^{2n+1} = -x^{2n+1}$ and $(-x)^{2n} = x^{2n}$ for all $n \in \mathbb{N}$, it follows directly from Equation \eqref{eq:sin_cos} that
\begin{align*}
	\sin(-x) &= -\sin(x) \text{ $\sin$ is an \textbf{odd} function},\\
	 \cos(-x) &= \cos(x) \text{ $\cos$ is an \textbf{even} function}.
\end{align*}

\begin{theorem}{From the Complex Exponential to Sine and Cosine}{cmplx_exp_sin_cos}
	For all $x \in \mathbb{R}$, the relations
	\[
		e^{ix} = \cos(x) + i\sin(x), \qquad \sin(x) = \frac{e^{ix} - e^{-ix}}{2i}, \qquad \cos(x) = \frac{e^{ix} + e^{-ix}}{2} 
	\]
	hold. For all $x, y \in \mathbb{R}$ the trigonometric addition formulas are
	\begin{align*}
		\sin(x + y) &= \sin(x)\cos(y) + \cos(x)\sin(y),\\
		 \cos(x + y) &= \cos(x)\cos(y) - \sin(x)\sin(y).
	\end{align*}
\end{theorem}

\subsubsection{The Circle Number}
\begin{theorem}{Existence of $\pi$ as the First Zero of Sine}{exist_pi_sin}
	There exists exactly one number $\pi \in (0, 4)$ such that $\sin(\pi) = 0$.
	For this number it holds that
	\[
		e^{i\frac{\pi}{2}} = i, \qquad e^{i\pi} = -1, \qquad e^{i2\pi} = 1.
	\]
\end{theorem}

\begin{corollary}{Periodicity of Sine and Cosine}{period_sin_cos}
	\begin{align*}
		\sin(x + \frac{\pi}{2}) &= \cos(x), \qquad \cos(x + \frac{\pi}{2}) = -\sin(x)\\
		\sin(x + \pi) &= -\sin(x), \qquad \cos(x + \pi) = -\cos(x),\\
		\sin(x + 2\pi) &= \sin(x), \qquad \cos(x + 2\pi) = \cos(x).
	\end{align*}
\end{corollary}

\subsubsection{Polar Coordinates and Multiplication of Complex Numbers}
Using the complex exponential function, we can express complex numbers in \textbf{polar coordinates}, i.e., in the form
\[
	z = re^{i\theta} = r \cos(\theta) + ir \sin(\theta),
\]
where $r = |z|$ is the distance of $z$ from the origin, and $\theta$ is the angle between the positive real axis $\mathbb{R}_{\geq0}$ and the segment from 0 to $z$. In other words, if $z = x + iy$, then
\[
	x = r\cos(\theta), \qquad y = r\sin(\theta), \qquad r = \sqrt{x^2 + y^2}.
\]
If $z \neq 0$, the angle $\theta$ is uniquely determined and is called the \textbf{argument} of $z$, denoted $\theta = \arg(z)$. The set of all complex numbers with absolute value 1 is
\[
	\mathbb{S}^1 = \{z \in \mathbb{C} \;|\; |z| = 1\} = \{e^{i\theta} \;|\; \theta \in [0, 2\pi)\},
\]
and is called the \textbf{unit circle} in $\mathbb{C}$.

\begin{proposition}{Existence of Polar Coordinates}{exist_polar_coord}
	For every $z \in \mathbb{C} \setminus \{0\}$, there exists uniquely determined real numbers $r > 0$ and $\theta \in [0, 2\pi)$ such that $z = r e^{i\theta}$.
\end{proposition}

In polar coordinates, multiplication of complex numbers takes a simple geometric form: if $z = re^{i\varphi}$ and $w = se^{i\psi}$, then
\[
	zw = rse^{i(\varphi + \psi)}.
\]
Thus, when multiplying two complex numbers, their magnitudes multiply and their arguments add.

\subsubsection{Other Trigonometric and Hyperbolic Functions}
In addition to sine and cosine functions, several related \textbf{trigonometric functions} are defined.

The \textbf{tangent} and \textbf{cotangent} functions are defined by
\[
	\tan(x) = \frac{\sin(x)}{\cos(x)}, \qquad \cot(x) = \frac{\cos(x)}{\sin(x)},
\]
for all $x \in \mathbb{R}$ such that the denominator are non-zero.

The \textbf{hyperbolic sine} and \textbf{hyperbolic cosine} are defined by the power series
\[
	\sinh(x) = \sum_{n=0}^{\infty} \frac{x^{2n+1}}{(2n+1)!}, \qquad \cosh(x) = \sum_{n=0}^{\infty} \frac{x^{2n}}{(2n)!}.
\]
Equivalently,
\[
	\sinh(x) = \frac{e^{ix} - e^{-ix}}{2}, \qquad \cosh(x) = \frac{e^{ix} + e^{-ix}}{2},
\]
and hence $e^{x} = \sinh(x) + \cosh(x)$ for all $x \in \mathbb{R}$.

The \textbf{hyperbolic tangent} and \textbf{hyperbolic cotangent} are defined by
\[
	\tanh(x) = \frac{\sinh(x)}{\cosh(x)} = \frac{e^{ix} - e^{-ix}}{e^{ix} + e^{-ix}}, \qquad \coth(x) = \frac{\cosh(x)}{\sinh(x)} = \frac{e^{ix} + e^{-ix}}{e^{ix} - e^{-ix}},
\]
where $\coth(x)$ is defined for all $x \in \mathbb{R}\setminus \{0\}$ (since $\sinh(x) \neq 0$ for all $x \neq 0$)

The functions $\sinh$ and $\tanh$ are odd, while $\cosh$ is even. Also, they satisfy the addition formulas
\begin{align*}
	\sinh(x+y) &= \sinh(x)  \cosh(y) + \cosh(x) \sinh(y),\\
	\cosh(x+y) &= \cosh(x) \cosh(y) + \sinh(x) \sinh(y),
\end{align*}
and the \textbf{hyperbolic identity}
\[
	\cosh^2(x) - \sinh^2(x) = 1 \qquad \forall x \in \mathbb{R}.
\]


