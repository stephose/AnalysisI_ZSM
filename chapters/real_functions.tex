%
% (c) 2025 Autor, ETH ZÃ¼rich
%
% !TEX root = main.tex
% !TEX encoding = UTF-8
%

\section{Functions of one Real Variable}
In this chapter we study real-valued functions defined on subsets of $\mathbb{R}$, typically intervals. The central concept is \textit{continuity}.

\subsection{Real valued functions}

\subsubsection{Boundedness and Monotonitcity}
For a non-empty set $D \subseteq \mathbb{R}$, the set of \textbf{real-valued} functions on $D$ is
\[
	\mathcal{F}(D) = \{f\;|\;f:D \to \mathbb{R}\}.
\]
For $f_1, f_2 \in \mathcal{F}(D)$, $\alpha \in \mathbb{R}$, and $x \in D$ we define
\[
	(f_1 + f_2)(x) = f_1(x) + f_2(x), \qquad (\alpha f_1)(x) = \alpha f_1(x), \qquad (f_1f_2)(x) = f_1(x)f_2(x).
\]
Given $\alpha \in \mathbb{R}$, we write $f \equiv \alpha$ for the constant function $x \mapsto \alpha$ on $D$.

\begin{remark}
	With the operations above, $\mathcal{F}(D)$ is a commutative ring (the additive identity is $f \equiv 0$ and the multiplicative identity is $f \equiv 1$).
\end{remark}

A point $x \in D$ is a \textbf{zero} of $f \in \mathcal{F}(D)$ if $f(x) = 0$. The \textbf{zero set} of $f$ is $\{x \in D\;|\; f(x) = 0\}$.
We order $\mathcal{F}(D)$ pointwise: for $f_1, f_2 \in \mathcal{F}(D)$,
\begin{align*}
	f_1 \leq f_2 \quad &\Leftrightarrow \quad f_1(x) \leq f_2(x) \quad \forall x \in D,\\
	f_1 < f_2 \quad &\Leftrightarrow \quad f_1(x) < f_2(x) \quad \forall x \in D.
\end{align*}
We say that $f \in \mathcal{F}(D)$ is \textbf{non-negative} if $f \geq 0$, and \textbf{positive} if $f > 0$.

\begin{definition}{Bounded Functions}{bounded_func}
	Let $D \neq \emptyset$ and $f:D \to \mathbb{R}$. We say that $f$ is \textbf{bounded from above} if there exists $M > 0$ such that
	\[
		f(x) \leq M \qquad \forall x \in D.
	\]
	We say that $f$ is \textbf{bounded from below} if there exists $M > 0$ such that
	\[
		f(x) \geq -M \qquad \forall x \in D.
	\]
	We say that $f$ is \textbf{bounded} if it is both bounded from above and from below. Equivalently, $f$ if bounded if there exists $M > 0$ such that
	\[
		|f(x)| \leq M \qquad \forall x \in D.
	\]
\end{definition}

\begin{definition}{Monotone Functions}{monotone_func}
	Let $D \subseteq \mathbb{R}$ and $f:D \to \mathbb{R}$. The function $f$ is:
	\begin{enumerate}
		\item \textbf{increasing} if $x < y \quad \Rightarrow \quad f(x) \leq f(y) \quad \forall x,y \in D$;
		\item \textbf{strictly increasing} if $x < y \quad \Rightarrow \quad f(x) < f(y) \quad \forall x,y \in D$;
		\item \textbf{decreasing} if $x < y \quad \Rightarrow \quad f(x) \geq f(y) \quad \forall x,y \in D$;
		\item \textbf{strictly decreasing} if $x < y \quad \Rightarrow \quad f(x) > f(y) \quad \forall x,y \in D$.
	\end{enumerate}
	We call $f$ \textbf{monotone} if it is increasing or decreasing, and \textbf{strictly monotone} if it is strictly increasing or strictly decreasing.
\end{definition}

\subsubsection{Continuity}

\begin{definition}{Continuous Functions}{cont_func}
	Let $D \subseteq \mathbb{R}$ and $f:D \to \mathbb{R}$. We say that $f$ is \textbf{continuous at} $x_0 \in D$ if for all $\varepsilon > 0$ there exists $\delta > 0$ such that
	\[
		\forall x \in D, \quad |x - x_0| < \delta \quad \Rightarrow \quad |f(x) - f(x_0)| < \varepsilon.
	\]
	We say that $f$ is \textbf{continuous on} $D$ if it is continuous at every point of $D$.
\end{definition}

\begin{remark}
	It suffices to verify the implication above for small $\varepsilon$. Precisely, assume there exists $\varepsilon_0 > 0$ such that for every $\varepsilon \in (0, \varepsilon_0]$ there is a $\delta > 0$ such that
	\[
		\forall x \in D, \quad |x - x_0| < \delta \quad \Rightarrow \quad |f(x) - f(x_0)| < \varepsilon.
	\]
	Then $f$ is continuous at $x_0$.
	
	Indeed, for $\varepsilon_0 > \varepsilon$ we can choose the number $\delta > 0$ corresponding to $\varepsilon$ to get
	\[
		\forall x \in D, \quad |x - x_0| < \delta \quad  \Rightarrow \quad |f(x) - f(x_0)| < \varepsilon < \varepsilon_0.
	\]
	In other words, if $\delta$ works for $\varepsilon$, then it works for all $\varepsilon_0 > \varepsilon$.
\end{remark}

\begin{definition}{Restriction}{restriction}
	Let $D \subseteq \mathbb{R}$ and $f:D \to \mathbb{R}$. For any $D' \subseteq D$ the \textbf{restriction} of $f$ to $D'$ is the function $f|_{D'}:D' \to \mathbb{R}$ defined by
	\[
		f|_{D'}(x) = f(x) \qquad \forall x \in D'.
	\]
	We regard $f|_{D'}$ and $f$ as different functions unless $D' = D$.
\end{definition}

\begin{proposition}{Combination of Continuous Functions}{comb_cont_func}
	Let $D \subseteq \mathbb{R}$, and let $f_1, f_2:D \to \mathbb{R}$ be continuous at $x_0 \in D$. Then $f_1 + f_2$, $f_1f_2$, and $\alpha f_1$ (for any $\alpha \in \mathbb{R}$) are continuous at $x_0$.
\end{proposition}

\begin{proof}
	We first prove the result for the sum. Let $\varepsilon > 0$. Since $f_1$ and $f_2$ are continuous at $x_0$, there exists $\delta_1, \delta_2 > 0$ such that for all $x \in D$,
	\[
		|x - x_0| < \delta_1 \; \Rightarrow \; |f_1(x) - f_1(x_0)| < \frac{\varepsilon}{2}, \quad |x - x_0| < \delta_2 \; \Rightarrow \; |f_2(x) - f_2(x_0)| < \frac{\varepsilon}{2}.
	\]
	So, choosing $\delta = \min{\delta_1, \delta_2}$, for $|x - x_0| < \delta$ we get
	\[
		|(f_1 + f_2)(x) - (f_1 + f_2)(x_0)| \leq |f_1(x) - f_1(x_0)| + |f_2(x) - f_2(x_0)| < \varepsilon,
	\]
	which shows that $f_1 + f_2$ is continuous at $x_0$.
	
	For the product, note that
	\begin{align*}
		|f_1(x)f_2(x) - f_1(x_0)f_2(x_0)| &= |f_1(x)f_2(x) - f_1(x_0)f_2(x) + f_1(x_0)f_2(x) - f_1(x_0)f_2(x_0)|\\
		&\leq |f_1(x)f_2(x) - f_1(x_0)f_2(x)| + |f_1(x_0)f_2(x) - f_1(x_0)f_2(x_0)|\\
		&= |f_2(x)||f_1(x) - f_1(x_0)| + |f_1(x_0)||f_2(x) - f_2(x_0)|.
	\end{align*}
	Now, first choose $\delta_0 > 0$ such that $|x - x_0| < \delta_0$ implies $|f_2(x) - f_2(x_0)| < 1$, so that
	\[
		|x - x_0| < \delta_0 \quad \Rightarrow \quad |f_2(x)| < 1 + |f_2(x_0)|.
	\]
	Then choose $\delta_1, \delta_2 > 0$ such that
	\begin{align*}
		|x - x_0| < \delta_1 \quad \Rightarrow \quad |f_1(x) - f_1(x_0)| < \frac{\varepsilon}{2 (1 + |f_2(x_0)|)},\\
		|x - x_0| < \delta_2 \quad \Rightarrow \quad |f_2(x) - f_2(x_0)| < \frac{\varepsilon}{2 (1 + |f_1(x_0)|)}.
	\end{align*}
	So choosing $\delta = \min{\delta_0, \delta_1, \delta_2}$, for $|x - x_0| < \delta$ we get
	\begin{align*}
		|f_1(x)f_2(x) - f_1(x_0)f_2(x_0)| &< |f_2(X)|\, \frac{\varepsilon}{2 (1 + |f_2(x_0)|)} + |f_1(x_0)|\, \frac{\varepsilon}{2 (1 + |f_1(x_0)|)}\\
		&< (1 + |f_2(x_0)|)\, \frac{\varepsilon}{2 (1 + |f_2(x_0)|)} + |f_1(x_0)|\, \frac{\varepsilon}{2 (1 + |f_1(x_0)|)}\\
		&< \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon,
	\end{align*}
	thus $f_1f_2$ is continuous at $x_0$.
	
	Finally, the statement about $\alpha f_1$ follows by choosing $f_2 \equiv \alpha$ (a constant function) and using the product case proved above: since $f_1$ and $f_2$ are continuous at $x_0$, their product $f_1f_2 = \alpha f_1$ is continuous at $x_0$. \qedhere
\end{proof}

\begin{definition}{Sum and Product Notation}{sum_prod_notation}
	Let $n \in \mathbb{N}$ and $a_0, a_1, \hdots , a_n \in \mathbb{R}$. We use the notation
	\[
		\sum_{j=0}^{n} a_j = a_0 + a_1 + \hdots + a_n, \qquad \prod_{j=0}^{n} a_0 \cdot a_1 \cdot \hdots \cdot a_n.
	\]
	Here $a_j$ is a \textbf{summand} in the sum and a \textbf{factor} in the product; $j$ is the \textbf{index} (or \textbf{running variable}).
	If $J$ is a finite set and numbers $(a_j)_{j\in J}$ are given, we write
	\[
		\sum_{j \in J} a_j, \qquad \prod_{j\in J} a_j.
	\]
	By convention, for the empty index set $\emptyset$,
	\[
		\sum_{j\in \emptyset} a_j = 0, \qquad \prod_{j\in \emptyset} a_j = 1.
	\]
\end{definition}

\begin{proposition}{Composition of Continuous Functions}{comp_cont_func}
	Let $D_1, D_2 \subseteq \mathbb{R}, x_0 \in D_1$ and $f:D_1 \to D_2$ be continuous at $x_0$. If $g:D_2 \to \mathbb{R}$ is continuous at $f(x_0)$, then $g \circ f:D_1 \to \mathbb{R}$ is continuous at $x_0$. In particular, the composition of continuous functions is continuous.
\end{proposition}

\begin{proof}
	Let $\varepsilon > 0$. By continuity of $g$ at $f(x_0)$, there exists $\eta > 0$ such that
	\[
		\forall y \in D_2, \quad |y - f(x_0)| < \eta \quad \Rightarrow \quad |g(y) - g(f(x_0))| < \varepsilon.
	\]
	By continuity of $f$ at $x_0$, there exists $\delta > 0$ such that
	\[
		\forall x \in D_1, \quad |x - x_0| < \delta \quad \Rightarrow \quad |f(x) - f(x_0)| < \eta.
	\]
	Combining the implications gives, for any $x \in D_1$,
	\[
		|x - x_0| < \delta \quad \Rightarrow \quad |f(x) - f(x_0)| < \eta \quad \Rightarrow \quad |g(f(x)) - g(f(x_0))| < \varepsilon. \qedhere
	\]
\end{proof}

\begin{remark}
	\label{rmk:modulus_cont}
	Applying Proposition \ref{prop*comp_cont_func} with $g(y) = |y|$, we see that if $f:D \to \mathbb{R}$ is continuous, then $x \mapsto |f(x)|$ is continuous.
\end{remark}

\subsubsection{Sequential Continuity}

\begin{definition}{Notation for Limits of Sequences}{notation_lim_seq}
	Let $(x_n)_{n=0}^{\infty} \subseteq \mathbb{R}$ and $\overline{x} \in \mathbb{R}$. We write
	\[
		x_n \to \bar{x} \qquad \text{or} \qquad x_n \underset{n \to \infty}{\longrightarrow} \bar{x}
	\] 
	to mean
	\[
		\lim_{n \to \infty} x_n = \bar{x}.
	\]
\end{definition}

\begin{theorem}{Continuity = Sequential Continuity}{cont_seq_cont}
	Let $D \subseteq \mathbb{R}$, $f:D \to \mathbb{R}$, and $\bar{x} \in D$. Then $f$ is continuous at $\bar{x}$ if and only if for every sequence $(x_n)_{n=0}^{\infty} \subseteq D$ with $x_n \to \bar{x}$ we have $f(x_n) \to f(\bar{x})$.  
\end{theorem}

\begin{proof}
	'$\Rightarrow$': First Assume that $f$ is continuous at $\bar{x}$. Then, given $\varepsilon > 0$, there exists $\delta > 0$ such that
	\[
		\forall x \in D, \quad |x - \bar{x}| < \delta \quad \Rightarrow \quad |f(x) - f(\bar{x})| < \varepsilon.
	\]
	Also, since $x_n \to \bar{x}$, there exists $N \in \mathbb{N}$ such that
	\[
		n \geq N \quad \Rightarrow \quad |x_n - \bar{x}| < \delta.
	\]
	Thus,
	\[
		n \geq N \quad \Rightarrow \quad |f(x_n) - f(\bar{x})| < \varepsilon,
	\]
	which implies that the sequence $(f(x_n))_{n=0}^{\infty}$ converges to $f(\bar{x})$.
	
	'$\Leftarrow$': To prove the converse, assume that $f$ is not continuous at $x_0$. This means that there exists $\varepsilon > 0$ such that, for every $\delta > 0$, there is $x \in D$ with
	\[
		|x - \bar{x}| < \delta \quad \text{and} \quad |f(x) - f(\bar{x})| \geq \varepsilon.
	\]
	Now, for every $n \in \mathbb{N}$, we apply this property with $\delta = 2^{-n}$ to find a point $x_n \in D$ such that
	\[
		|x_n - \bar{x}| < 2^{-n} \quad \text{and} \quad |f(x_n) - f(\bar{x})| \geq \varepsilon
	\]
	Then the sequence constructed in this way satisfies $x_n \to \bar{x}$ but $f(x_n) \not\to f(\bar{x})$. \qedhere
\end{proof}

\begin{remark}
	\label{rmk:neg_seq_cont}
	The proof above shows that if $f:D \to \mathbb{R}$ is not continuous at $\bar{x}$, then there exists $\varepsilon > 0$ and a sequence $(x_n)_{n=0}^{\infty} \subseteq D$ with $x_n \to \bar{x}$ such that $|f(x_n) - f(\bar{x})| \geq \varepsilon$ for all $n \in \mathbb{N}$. This is useful to show that a function $f$ is not continuous at $\bar{x}$.   
\end{remark}

\subsection{Continuous Functions}

\subsubsection{Intermediate Value Theorem}
In this section we prove a fundamental theorem that formalizes the idea that the graph of a continuous function on an interval is a continuous curve, and thus cannot make any jumps.

\begin{theorem}{Intermediate Value Theorem}{int_val_theo}
	Let $f:[a, b] \to \mathbb{R}$ be a continuous function with $f(a) \leq f(b)$. Then, for every real number $c$ with $f(a) \leq c \leq f(b)$, there exists $\bar{x} \in [a, b]$ such that $f(\bar{x}) = c$.
\end{theorem}

\begin{proof}
	Fix $c \in [f(a), f(b)]$. Then define
	\[
		X = \{x \in [a, b] \;|\; f(x) \leq c\}.
	\]
	Since $a \in X$ and $X \subseteq [a, b]$, the set is non-empty and bounded from above. By Theorem \ref{theo*sup_exist}, its supremum
	\[
		\bar{x} = sup(X) \in [a, b]
	\]
	exists.
	We now use the continuity of $f$ at $x_0$ to show that $f(\bar{x}) = c$.
	
	Since $\bar{x}$ is the supremum of $X$, for each $n \geq 0$, we can find a point $x_n \in [\bar{x} - 2^{-n}, \bar{x}]$.
	Then $|x_n - \bar{x}| \leq 2^{-n}$, hence $x_n \longrightarrow \bar{x}$.
	Also, by the definition of $X$, we have $f(x_n) \leq c$. Thus, by Theorem \ref{theo*cont_seq_cont} (continuity of $f$ along sequences),
	\[
		\lim_{n \to \infty} f(x_n) = f(\bar{x}).
	\]
	And Proposition \ref{prop*lim_ineq} yields $\lim_{n \to \infty} f(x_n) \leq c$. Therefore, $f(\bar{x}) \leq c$.
	
	Suppose, by contradiction, $f(\bar{x}) < c$ and set $\varepsilon := c - f(\bar{x}) > 0$. By continuity at $\bar{x}$, there exists $\delta > 0$ such that for all $x \in [a, b]$
	\[
		|x - \bar{x}| < \delta \quad \Rightarrow \quad |f(x) - f(\bar{x})| < \varepsilon,
	\]
	hence $f(x) < f(\bar{x}) + \varepsilon = c$. 
	Therefore, by the definition of $X$,
	\[
		(\bar{x} - \delta, \bar{x} + \delta) \cap [a, b] \subseteq X.
	\]
	Moreover, since $f(\bar{x}) < c \leq f(b)$, we cannot have $\bar{x} = b$; hence $\bar{x} < b$.
	Because $\bar{x} < b$, the interval $(\bar{x} , \bar{x} + \delta) \cap [a, b] \subseteq X$ is non-empty.
	Pick 
	\[
		y \in (\bar{x}, \bar{x} + \delta) \cap [a, b] \subseteq X.
	\]
	Then $y \in X$ and $y > \bar{x}$, which contradicts the defining property of the supremum: $\bar{x}$ is an upper bound of $X$, and $X$ cannot contain elements larger than $\bar{x}$. This contradiction shows that $f(\bar{x}) \geq c$. Together with $f(\bar{x}) \leq c$ proved above, we conclude that $f(\bar{x}) = c$, as desired. \qedhere
\end{proof}

\begin{theorem}{Inverse Function Theorem}{inv_func_theo}
	Let $I$ be an interval and $f: I \to \mathbb{R}$ a continuous strictly monotone function. Then $f(I)$ is an interval, and the mapping $f:I \to f(I)$ has a continuous strictly monotone inverse function $f^{-1}:f(I) \to I$.
\end{theorem}

\begin{proof}
	We may assume that $I$ is non-empty and not a single point.
	Also, w.l.o.g, suppose $f$ is strictly increasing (otherwise replace $f$ with $-f$).
	
	Let $J = f(I)$. Since $f$ is strictly monotone it is injective. Also, since by definition $J = f(I)$, it is surjective, hence bijective. 
	Therefore there exists a unique inverse $g = f^{-1}:J \to I$.
	
	Because $f$ is strictly increasing, we have
	\begin{equation}
		\label{eq:f_strict_incr}
		x_1 < x_2 \quad \Leftrightarrow \quad f(x_1) < f(x_2) \qquad \forall x_1, x_2 \in I.
	\end{equation}
	(Note: here we have equivalence in the statements because $f$ is both injective and strictly increasing)
	Defining $y_1 = f(x_1)$ and $y_2 = f(x_2)$, this is equivalent to
	\[
		y_1 < y_2 \quad \Leftrightarrow \quad g(y_1) < g(y_2) \qquad \forall y_1, y_2 \in J
	\]
	Thus, $g$ is strictly increasing.
	
	To show that $J$ is an interval, $y_1, y_2 \in J$, and assume w.l.o.g that $y_ 1 < y_2$. Since, $J = f(I)$, Equation \ref{eq:f_strict_incr} implies that $y_1 = f(x_1), y_2 = f(x_2)$ for some $x_1, x_2 \in I$ with $x_1 < x_2$.
	Now by the Intermediate Value Theorem \ref{theo*int_val_theo} applied to $f:[x_1, x_2] \to \mathbb{R}$, we have that all values $c \in [y_1, y_2]$ are in the image of $f:[x_1, x_2] \to \mathbb{R}$, i.e.,
	\[
		[y_1, y_2] \subseteq f([x_1, x_2]) \subseteq J.
	\]
	Since, $y_1, y_2$ were two arbitrary points in $J$, this proves that $J$ is an interval.
	
	It remains to show that $g = f^{-1}$ is continuous. 
	Fix $\bar{y} \in J$ and suppose, by contradiction, that $g$ is not continuous at $\bar{y}$. Then by Remark \ref{rmk:neg_seq_cont}, there exists $\varepsilon > 0$ and a sequence $(y_n)_{n=0}^{\infty} \subseteq J$ such that
	\begin{equation}
		\label{eq:g_not_cont}
		y_n \longrightarrow \bar{y} \qquad \text{but} \qquad |g(y_n) - g(\bar{y})| \geq \varepsilon \quad \forall n \in \mathbb{N}.
	\end{equation}
	Set $x_n = g(y_n) \in I$ and $\bar{x} = g(\bar{y}) \in I$.
	Then for every $n \in \mathbb{N}$, either $x_n \leq \bar{x} - \varepsilon$ or $x_n \geq \bar{x} + \varepsilon$.
	In particular, at least one of these cases must occur infinitely often. W.l.o.g, assume $x_n \leq \bar{x} - \varepsilon$ for infinitely many $n$, and extract a subsequence $(x_{n_k})_{k=0}^{\infty}$ with $x_{n_k} \leq \bar{x} - \varepsilon$ for all $k$. 
	Since, $I$ is an interval, $\bar{x} - \varepsilon \in I$, and by strict monotonicity of $f$ we obtain
	\[
		y_{n_k} = f(x_{n_k}) \leq f(\bar{x} - \varepsilon) < f(\bar{x}) = \bar{y}.	
	\]
	Then Proposition \ref{prop*lim_ineq} gives (recall $y_n \longrightarrow \bar{y}$, see \ref{eq:g_not_cont})
	\[
		\bar{y} = \lim_{k \to \infty} y_{n_k} \leq f(\bar{x} - \varepsilon) < f(\bar{x}) = \bar{y},
	\]
	a contradiction. Hence, $g$ is continuous. \qedhere
\end{proof}

\subsection{Continuous Functions on Compact Intervals}
In this section we show that continuous functions on \textbf{bounded closed} intervals, called \textbf{compact intervals}, enjoy special properties.

\subsubsection{Boundedness and Extrema}

\begin{lemma}{Compactness}{compact}
	Let $[a, b]$ be a compact interval, and let $(x_n)_{n=0}^{\infty}$ be a sequence contained in $[a, b]$.
	Then there exists a subsequence $(x_{n_k})_{k=0}^{\infty}$ such that
	\[
		\lim_{k \to \infty} x_{n_k} = \bar{x} \qquad \text{for some } \bar{x} \in [a, b].
	\]
\end{lemma}

\begin{proof}
	Since $(x_n)_{n=0}^{\infty}$ is bounded (as it lies in $[a, b]$), Corollary \ref{cor*bound_seq_conv_subseq} ensures the existence of a convergent subsequence $(x_{n_k})_{k=0}^{\infty}$. Let $\bar{x}$ denote its limit. Because $a \leq x_{n_k} \leq b$ for all k, Proposition \ref{prop*lim_ineq} yields $a \leq \bar{x} \leq b$. \qedhere
\end{proof}

\begin{theorem}{Boundedness}{boundedness}
	Let $[a, b]$ be compact interval, and let $f:[a, b] \to \mathbb{R}$ be continuous. Then $f$ is bounded.
\end{theorem}

\begin{proof}
	Assume by contradiction that $f$ is unbounded. Then, for every $n \in \mathbb{N}$, there exists $x_n \in [a, b]$ such that $|f(x_n)| \geq n$. By Lemma \ref{lem*compact}, there is a subsequence $(x_{n_k})_{k=0}^{\infty}$ converging to some $\bar{x} \in [a, b]$.
	
	Since $f$ is continuous, so is $|f|$ (recall Remark \ref{rmk:modulus_cont}), therefore $|f(x_{n_k})| \longrightarrow |f(\bar{x})| \in \mathbb{R}$. This contradicts $|f(x_{n_k})| \geq n_k \longrightarrow \infty$, so $f$ must be bounded. \qedhere
\end{proof}

\begin{exercise}
	Find examples of:
	\begin{enumerate}
		\item a continuous but unbounded function on a bounded \textit{open} interval.
		\[
			f:(0, 1) \to \mathbb{R},\; x \mapsto \frac{1}{x}.
		\]
		\item a continuous but unbounded function on an \textit{unbounded closed} interval.
		\[
			f:[0, \infty) \to \mathbb{R},\; x \mapsto x.
		\]
		\item an unbounded function on a compact interval but discontinuous at only one point.
		\[
			f:[0, 1] \to \mathbb{R},\; x \mapsto \begin{cases}
				\frac{1}{x}, \quad &\text{for } x \neq 0\\
				a \in \mathbb{R}, \quad &\text{for } x = 0.
			\end{cases}
		\]
	\end{enumerate}
\end{exercise}

\begin{definition}{Extreme Values}{extreme_val}
	Let $D \subseteq \mathbb{R}$ and $f: D \to \mathbb{R}$.
	\begin{itemize}
		\item[$\bullet$] We say that $f$ takes its \textbf{maximum value} at $x_0 \in D$ if $f(x) \leq f(x_0)$ for all $x \in D$.
		Then $f(x_0)$ is the \textbf{maximum} of $f$.
		\item[$\bullet$] We say that $f$ takes its \textbf{minimum value} at $x_0 \in D$ if $f(x) \geq f(x_0)$ for all $x \in D$.
		Then $f(x_0)$ is the \textbf{minimum} of $f$.
	\end{itemize}
	Maxima and minima ar called \textbf{extreme values} or \textbf{extrema}.
\end{definition}

\begin{theorem}{Extreme Value Theorem}{extreme_val_theo}
	Let $[a, b]$ be a compact interval, and let $f:[a, b] \to \mathbb{R}$ be continuous. Then $f$ attains both its minimum and its maximum.
\end{theorem}

\begin{proof}
	Theorem \ref{theo*boundedness} guarantees that $f$ is bounded, or equivalently, that $f([a, b]) \subseteq \mathbb{R}$ is a bounded subset of $\mathbb{R}$. Thus, Theorem \ref{theo*sup_exist} implies that
	\[
		S := \sup f([a, b])
	\]
	exists.
	By definition of the supremum, for each $n \in \mathbb{N}$ there exists $y_n \in f([a, b])$ such that $S - 2^{-n} \leq y_n \leq S$. Hence, $y_n \to S$. Also, since $y_n \in f([a, b])$, there exists $x_n \in [a, b]$ such that $f(x_n) = y_n$.
	
	Now, by Lemma \ref{lem*compact}, we can find a subsequence $(x_{n_k})_{k=0}^{\infty}$ such that $x_{n_k} \to \bar{x} \in [a, b]$. By continuity of $f$, we have that
	\[
		f(\bar{x}) = \lim_{k \to \infty} f(x_{n_k}) = \lim_{k \to \infty} y_{n_k} = S,
	\]
	so $f$ attains its maximum at $\bar{x}$.
	
	Applying the same reasoning to $-f$ shows that $f$ also attains its minimum. \qedhere
\end{proof}

\subsubsection{Uniform Continuity}

\begin{definition}{Uniform Continuity}{unif_cont}
	Let $D \subseteq \mathbb{R}$. A function $f:D \to \mathbb{R}$ is \textbf{uniformly continuous} if, for every $\varepsilon > 0$, there exists $\delta > 0$ such that
	\[
		|x - y| < \delta \quad \Rightarrow \quad |f(x) - f(y)| < \varepsilon \qquad \forall x,y \in D.
	\]
\end{definition}

\begin{remark}
	The difference between the usual definition of continuity and the one of uniform continuity lies in how the choice of $\delta$ depends on the points considered.
	
	For a function that is continuous at each $x_0 \in D$, the $\delta$ in the definition may depend on both $\varepsilon$ \textbf{and} $x_0$: for every $\varepsilon > 0$ and each $x_0$, we can find a $\delta = \delta(\varepsilon, x_0)$ that works near $x_0$.
	
	Uniform continuity is stronger: there exists a single $\delta = \delta(\varepsilon)$ that works \textbf{simultaneously} for all $x, y \in D$. In other words, the control on the variation of $f$ does not deteriorate as we move along the domain. This property is automatically satisfied on compact intervals for continuous functions, as we will prove below.
\end{remark}

\begin{theorem}{Uniform Continuity on Compact Intervals}{unif_cont_compact_int}
	Let $[a, b]$ be a compact interval, and $f:[a, b] \to \mathbb{R}$ continuous on $[a, b]$. Then $f$ is uniformly continuous.
\end{theorem}

\begin{proof}
	Assume, by contradiction, that $f$ is not uniformly continuous on $[a, b]$. Then there exists $\varepsilon > 0$ such that for every $\delta > 0$ one can find $x, y \in [a, b]$ with
	\[
		|x - y| < \delta \quad \text{and} \quad |f(x) - f(y)| \geq \varepsilon.
	\]
	Taking $\delta = 2^{-n}$ for each $n \in \mathbb{N}$, we obtain sequences $(x_n)_{n=0}^{\infty}$ and $(y_n)_{n=0}^{\infty}$ in $[a, b]$ with
	\begin{equation}
		\label{eq:contra_unif_cont}
		|x_n - y_n| < 2^{-n} \quad \text{and} \quad |f(x_n) - f(y_n)| \geq \varepsilon.
	\end{equation}
	By Lemma \ref{lem*compact}, the sequence $(x_n)_{n=0}^{\infty}$ has a subsequence $(x_{n_k})_{k=0}^{\infty}$ converging to some $\bar{x} \in [a, b]$. Then
	\[
		|y_{n_k} - \bar{x}| \leq |y_{n_k} - x_{n_k}| + |x_{n_k} - \bar{x}| < 2^{-n_k} + |x_{n_k} - \bar{x}| \underset{k \to \infty}{\longrightarrow} 0,
	\]
	so $y_{n_k} \to \bar{x}$ as well. Thus, by continuity of $f$ and Theorem \ref{theo*cont_seq_cont}, we have that
	\[
		\lim_{k \to \infty} f(x_{n_k}) = \lim_{k \to \infty} f(y_{n_k}) = f(\bar{x}),
	\]
	therefore,
	\[
		|f(x_{n_k}) - f(y_{n_k})| \leq |f(x_{n_k}) - f(\bar{x})| + |f(\bar{x}) - f(y_{n_k})| \underset{k \to \infty}{\longrightarrow} 0,
	\]
	which contradicts Equation \ref{eq:contra_unif_cont}. Hence, $f$ is uniformly continuous on $[a, b]$. \qedhere
\end{proof}

\begin{definition}{Lipschitz Continuity}{lip_cont}
	Let $D \subseteq \mathbb{R}$, and $f: D \to \mathbb{R}$. We say that $f$ is \textbf{Lipschitz continuous} if there exists $L \geq 0$ such that
	\[
		|f(x) - f(y)| \leq L|x - y| \qquad \forall x, y \in D.
	\]
\end{definition}

\begin{lemma}{Lipschitz Continuity $\Rightarrow$ Uniform Continuity}{lip_cont_unif_cont}
	Let $D \subseteq \mathbb{R}$, and $f:D \to \mathbb{R}$ be a Lipschitz continuous function. Then $f$ is uniformly continuous.
\end{lemma}

\begin{proof}
	Let $D \subseteq \mathbb{R}$ and assume that $f:D \to \mathbb{R}$ is a Lipschitz continuous function. Then there exists $L \geq 0$ such that
	\[
		|f(x) - f(y)| \leq L|x - y| \qquad \forall x, y \in D.
	\]
	Now, fix $\varepsilon > 0$. We assume that $L \neq 0$ (otherwise the result follows immediately) and choose $\delta = \frac{\varepsilon}{L}$.
	Because of the Lipschitz continuity of $f$, we have that for all $x, y \in D$ it holds that
	\begin{align*}
		|x - y| < \delta = \frac{\varepsilon}{L} \quad \Leftrightarrow \quad L|x - y| < \varepsilon\\
		\Rightarrow \qquad |f(x) - f(y)| \leq L|x - y| < \varepsilon,
	\end{align*}
	which shows that $f$ is also uniformly continuous.\qedhere
\end{proof}


\subsection{Example: Expential and Logarithmic Functions}

\subsubsection{Definition of the Exponential Function}

\begin{lemma}{Bernoulli's Inequality}{bernoulli_ineq}
	For all $a \in \mathbb{R}$ with $a \geq -1$ and all $n \in \mathbb{N}$ with $n \geq 1$, it holds that
	\[
		(1 + a)^{n} \geq 1 + na.
	\]
\end{lemma}

\begin{proof}
	We proceed by induction. For $n = 1$ we have $(1 + a)^1 = 1 + a = 1 + 1 \cdot a$.
	
	Now assume that the inequality holds for some $n \geq 1$. Since $1 + a \geq 0$ by assumption, we find
	\[
		(1 + a)^{n + 1} = (1 + a)^n (1 + a) \geq (1 + n a) (1 + a) = 1 + na + a + na^2 \geq 1 + (n + 1)a,
	\]
	which establishes the induction step and completes the proof. \qedhere
\end{proof}

\begin{proposition}{Existence of the Exponential}{exp_exist}
	Let $x \in \mathbb{R}$. The sequence $(a_n)_{n=1}^{\infty}$ defined by
	\[
		a_n = \left(1 + \frac{x}{n}\right)^n
	\]
	is convergent, and its limit is a positive real number.
\end{proposition}

\begin{lemma}{Monotonicity}{exp_mono}
	Given $x \in \mathbb{R}$, let $n_0 \in \mathbb{N}$ satisfy $n_0 \geq 1$ and $n_0 > -x$. Then the sequence $(a_n)_{n=n_0}^{\infty}$ defined in Proposition \ref{prop*exp_exist} is increasing.
\end{lemma}

\begin{definition}{Exponential Function}{exp}
	The \textbf{exponential function} $\exp:\mathbb{R} \to \mathbb{R}_{>0}$ is defined by
	\[
		\exp(x) = \lim_{n \to \infty} \left(1 + \frac{x}{n}\right)^n \qquad \forall x \in \mathbb{R}.
	\]
\end{definition}

\begin{corollary}{Growth of the Exponential}{growth_exp}
	Given $n \in \mathbb{N}$ with $n \geq 1$, the exponential function satisfies
	\[
		\exp(x) \geq \left(1 + \frac{x}{n}\right)^n \qquad \forall x > -n.
	\]
\end{corollary}

\begin{proof}
	By Lemma \ref{lem*exp_mono} and Definition \ref{def*exp}, for $x > -n$ we have
	\[
		a_n \leq a_{n+1} \leq \hdots \leq \exp(x). \qedhere
	\]
\end{proof}

\subsubsection{Properties of the Exponential Function}

\begin{theorem}{Properties of the Exponential Function}{exp_properties}
	The exponential function $\exp:\mathbb{R} \to \mathbb{R}_{>0}$ is bijective, strictly increasing, and continuous. Moreover,
	\begin{align*}
		\exp(0) &= 1,\\
		\exp(-x) &= \exp(x)^{-1},\\
		\exp(x + y) &= \exp(x)\exp(y),
	\end{align*}
	for all $x, y \in \mathbb{R}$.
\end{theorem}

\subsubsection{The Natural Logarithm}
\begin{definition}{Logarithm}{log}
	The unique inverse function
	\[
		\log:\mathbb{R}_{>0} \to \mathbb{R}
	\]
	of the bijective map $exp:\mathbb{R} \to \mathbb{R}_{>0}$ is called the \textbf{logarithm}.
\end{definition}

\begin{corollary}{Properties of the Logarithm}{log_properties}
	The logarithm $\log:\mathbb{R}_{>0} \to \mathbb{R}$ is strictly increasing, continuous, and bijective. Moreover,
	\begin{align*}
		\log(1) &= 0,\\
		\log(a^{-1}) &= -\log(a),\\
		\log(ab) &= \log(a) + \log(b),
	\end{align*}
	for all $a, b \in \mathbb{R}_{>0}$.
\end{corollary}

The logarithm defined here is also called the \textbf{natural logarithm} to distinguish it from logarithms with another \textbf{base} $a > 1$ (for instance $a = 10$ or $a = 2$). For any $a > 1$, we define
\[
	\log_a(x) = \frac{\log(x)}{\log(a)} \qquad \forall x > 0.
\]
Unless stated otherwise, $\log(x)$ always denotes the natural logarithm, i.e., the logarithm to base $e$.

We can now define powers with arbitrary real exponents. For $a > 0$ and $x \in \mathbb{R}$ we set
\[
	a^x = \exp(x\,\log(a)).
\]

\subsection{Limits of Functions}
We consider functions $f:D \to \mathbb{R}$ defined on a subset $D \subseteq \mathbb{R}$, and we wish to define the limit of $f(x)$ as $x \in D$ approaches a point $x_0 \in \mathbb{R}$. Typical examples include $D = \mathbb{R}, D = [0, 1]$ or $D = (0, 1)$, with $x_0 = 0$ in each case.

\subsubsection{Limit in the Vicinity of a Point}
Let $D \subseteq \mathbb{R}$ be non-empty, and let $x_0 \in \mathbb{R}$ be such that
\begin{equation}
	\label{eq:acc_pt}
	D \cap (x_0 - \delta, x_0  + \delta) \neq \emptyset
\end{equation}
for all $\delta > 0$. Whenever this holds, we say that $x_0$ is an \textbf{accumulation point} of $D$. Note that if $x_0 \in D$, then Equation \ref{eq:acc_pt} is automatically satisfied.

Condition \ref{eq:acc_pt} ensures that there exists a sequence of points in $D$ converging to $x_0$.

\begin{definition}{Limit of a Function}{lim_func}
	Let $f:D \to \mathbb{R}$, and $x_0$ be an accumulation point of $D$.
	A number $L \in \mathbb{R}$ is called the \textbf{limit of} $f(x)$ \textbf{as} $x \to x_0$ if, for every $\varepsilon > 0$, there exists $\delta > 0$ such that
	\[
		|x - x_0| < \delta \quad \Rightarrow \quad |f(x) - L| < \varepsilon \qquad \forall x \in D.
	\]
\end{definition}



